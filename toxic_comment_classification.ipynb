{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('C:/Users/DENVER/Udacity/machine-learning\\projects/toxic-comment-classification/train.csv')#load the dataset\n",
    "test_data = pd.read_csv('C:/Users/DENVER/Downloads/test.csv/test.csv')\n",
    "data.head() # have a look at the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comment_text'].isnull().any() # check for empty entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# function to remove stop-words, numbers, and punctuation from comments\n",
    "def clean_data(data):\n",
    "    clean_data = [] \n",
    "    for text in data:\n",
    "        text = text_to_word_sequence(text)\n",
    "        text = [word for word in text if  word.isalpha() and word not in stop_words]\n",
    "        clean_data.append(text)\n",
    "\n",
    "    return clean_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and testing sets\n",
    "comments_train, comments_test, labels_train, labels_test = train_test_split(data['comment_text'],\\\n",
    "                data[['toxic','severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean train and test data \n",
    "comments_train = clean_data(comments_train)\n",
    "comments_test = clean_data(comments_test)\n",
    "kaggle_data = clean_data(test_data['comment_text'])#keep this one for kaagle score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import keras library for preprocessing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_words = 20000  # maximum number of common wards to be considered\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(comments_train) # fit tokenizer on comments_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn senteces into sequences \n",
    "tokenized_comments_train = tokenizer.texts_to_sequences(comments_train)\n",
    "tokenized_comments_test = tokenizer.texts_to_sequences(comments_test)\n",
    "tokenized_kaggle_data = tokenizer.texts_to_sequences(kaggle_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2900a08c828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize data to see distribution of number of  wards in comments \n",
    "senteces_length = [len(comment) for comment in tokenized_comments_train]\n",
    "\n",
    "plt.hist(senteces_length, bins=np.arange(0, 400, 10))\n",
    "plt.ylabel('Number of comments')\n",
    "plt.xlabel('Number of words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn senteces to the same lenght(maxlen)\n",
    "comments_length = 150 # max length for each comment \n",
    "pad_comments_train = pad_sequences(tokenized_comments_train, maxlen=comments_length )\n",
    "pad_comments_test = pad_sequences(tokenized_comments_test, maxlen=comments_length)\n",
    "pad_kaggle_data = pad_sequences(tokenized_kaggle_data, maxlen=comments_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model and layers from keras library \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D,  Reshape, Flatten\n",
    "from keras.layers import LSTM, GRU, Bidirectional, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 100, input_length=comments_length)) #, weights=[embedding_matrix], trainable=False))\n",
    "#model.add(Reshape((1,200,128)))\n",
    "#model.add(Conv1D(filters=20,kernel_size=2, padding='same', activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Conv2D(filters=20,kernel_size=2, padding='same', activation='relu'))\n",
    "#model.add(Bidirectional(LSTM(80, return_sequences=True)))\n",
    "#model.add(Bidirectional(GRU(60,return_sequences=True)))\n",
    "model.add(LSTM(60,return_sequences=True))\n",
    "model.add(GRU(60,return_sequences=True))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dense(60, activation='softmax'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.h5py', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(pad_comments_train,labels_train, epochs=3,validation_split=0.1, callbacks=[checkpointer], batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 107710 samples, validate on 11968 samples\n",
      "Epoch 1/5\n",
      "107710/107710 [==============================] - 615s 6ms/step - loss: 0.1617 - acc: 0.9636 - val_loss: 0.1463 - val_acc: 0.9619\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14629, saving model to weights.best.h5py\n",
      "Epoch 2/5\n",
      "107710/107710 [==============================] - 8802s 82ms/step - loss: 0.1407 - acc: 0.9636 - val_loss: 0.1463 - val_acc: 0.9619\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14629 to 0.14627, saving model to weights.best.h5py\n",
      "Epoch 3/5\n",
      "107710/107710 [==============================] - 627s 6ms/step - loss: 0.1407 - acc: 0.9636 - val_loss: 0.1462 - val_acc: 0.9619\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "\n",
      "Epoch 00003: val_loss improved from 0.14627 to 0.14624, saving model to weights.best.h5py\n",
      "Epoch 4/5\n",
      "107710/107710 [==============================] - 624s 6ms/step - loss: 0.1406 - acc: 0.9636 - val_loss: 0.1462 - val_acc: 0.9619\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "\n",
      "Epoch 00004: val_loss improved from 0.14624 to 0.14622, saving model to weights.best.h5py\n",
      "Epoch 5/5\n",
      " 23400/107710 [=====>........................] - ETA: 8:22 - loss: 0.1451 - acc: 0.962"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-70a5eef80097>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m          \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroc_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                         \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mprev_total_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\b'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                 \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mevent_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send (zmq\\backend\\cython\\socket.c:7305)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send (zmq\\backend\\cython\\socket.c:7048)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy (zmq\\backend\\cython\\socket.c:2920)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq\\backend\\cython\\socket.c:9621)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "x_val = comments_train[120000:]\n",
    "y_val = labels_train[107710:]\n",
    "x_train = comments_train[:107710]\n",
    "y_train = labels_train[:107710]\n",
    "\n",
    "\n",
    "model.fit(x_train,y_train, validation_data=(x_val, y_val), epochs=5, batch_size=50, verbose=1,\\\n",
    "          callbacks=[roc_callback(training_data=(x_train,y_train),validation_data=(x_val, y_val)), checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre = model.predict(pad_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(comments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.30993235  0.09459998  0.22915576  0.0549183   0.21933208  0.09206153]\n"
     ]
    }
   ],
   "source": [
    "print(pre[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41676765809861677"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = []\n",
    "for i in range(5):\n",
    "    roc_auc.append(roc_auc_score(labels_test.iloc[:,i], predictions[:,i]))\n",
    "    \n",
    "sum(roc_auc)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(pre, index=test_data['id'],\\\n",
    "                          columns=['toxic','severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])\n",
    "submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
