{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('C:/Users/DENVER/Udacity/machine-learning\\projects/toxic-comment-classification/train.csv')#load the dataset\n",
    "test_data = pd.read_csv('C:/Users/DENVER/Downloads/test.csv/test.csv')\n",
    "data.head() # have a look at the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               False\n",
       "comment_text     False\n",
       "toxic            False\n",
       "severe_toxic     False\n",
       "obscene          False\n",
       "threat           False\n",
       "insult           False\n",
       "identity_hate    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any() # check for empty entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# remove stop-words, numbers, and punctuation\n",
    "def clean_data(data):\n",
    "    clean_data = [] \n",
    "    for text in data:\n",
    "        text = text_to_word_sequence(text)\n",
    "        text = [word for word in text if  word.isalpha() ] #word not in stop_words and\n",
    "        clean_data.append(text)\n",
    "\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and testing sets\n",
    "comments_train, comments_test, labels_train, labels_test = train_test_split(data['comment_text'],\\\n",
    "                data[['toxic','severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']], test_size=0.2, random_state=42)\n",
    "\n",
    "commennts_train = clean_data(comments_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras library for preprocessing\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "max_words = 20000  # maximum number of common wards to be considered\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(comments_train) # fit tokenizer on comments_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# turn senteces into sequences \n",
    "tokenized_comments_train = tokenizer.texts_to_sequences(comments_train)\n",
    "#tokenized_comments_test = tokenizer.texts_to_sequences(comments_test)\n",
    "#tokenized_test_data = tokenizer.texts_to_sequences(test_data['comment_text'])\n",
    "#tokenized_clean_data = tokenizer.texts_to_sequences(data['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTJJKREQ0JkklIiIak6QSERGN+f8i+EaSiY6kVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19755dd0c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize data\n",
    "senteces_length = [len(comment) for comment in tokenized_comments_train]\n",
    "\n",
    "plt.hist(senteces_length, bins=np.arange(0, 400, 10))\n",
    "plt.ylabel('Number of comments')\n",
    "plt.xlabel('Number of words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn senteces to the same lenght(maxlen)\n",
    "comments_length = 200\n",
    "pad_comments_train = pad_sequences(tokenized_comments_train, maxlen=comments_length )\n",
    "#pad_comments_test = pad_sequences(tokenized_comments_test, maxlen=comments_length)\n",
    "#pad_test_data = pad_sequences(tokenized_test_data, maxlen=comments_length)\n",
    "#pad_clean_data = pad_sequences(tokenized_clean_data,maxlen=comments_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedReader.close>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load GloVe word embedding file into the memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.twitter.27B.200d.txt','rb')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "    \n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in comments_train\n",
    "embedding_matrix = np.zeros((max_words,200))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 200, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 200, 60)           38640     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 200, 60)           21780     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_14 (Glo (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 6)                 366       \n",
      "=================================================================\n",
      "Total params: 2,064,446\n",
      "Trainable params: 2,064,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D,  Reshape, Flatten\n",
    "from keras.layers import LSTM, GRU, Bidirectional, BatchNormalization # SpatialDropout1d,\n",
    "\n",
    "#np.random.seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 100, input_length=comments_length)) #, weights=[embedding_matrix], trainable=False))\n",
    "#model.add(Reshape((1,200,128)))\n",
    "#model.add(SpatialDropout1D(0.5))\n",
    "#model.add(Conv1D(filters=20,kernel_size=2, padding='same', activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Conv2D(filters=20,kernel_size=2, padding='same', activation='relu'))\n",
    "#model.add(Bidirectional(LSTM(80, return_sequences=True)))\n",
    "#model.add(Bidirectional(GRU(60,return_sequences=True)))\n",
    "model.add(LSTM(60,return_sequences=True))\n",
    "model.add(GRU(60,return_sequences=True))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dense(60, activation='softmax'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114890 samples, validate on 12766 samples\n",
      "Epoch 1/3\n",
      "114890/114890 [==============================] - 1867s 16ms/step - loss: 0.0810 - acc: 0.9757 - val_loss: 0.0521 - val_acc: 0.9809\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05214, saving model to weights.best.h5py\n",
      "Epoch 2/3\n",
      " 11280/114890 [=>............................] - ETA: 26:47 - loss: 0.0487 - acc: 0.9821"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.h5py', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(pad_comments_train,labels_train, epochs=3,validation_split=0.1, callbacks=[checkpointer], batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 107710 samples, validate on 11968 samples\n",
      "Epoch 1/5\n",
      "107710/107710 [==============================] - 615s 6ms/step - loss: 0.1617 - acc: 0.9636 - val_loss: 0.1463 - val_acc: 0.9619\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14629, saving model to weights.best.h5py\n",
      "Epoch 2/5\n",
      "107710/107710 [==============================] - 8802s 82ms/step - loss: 0.1407 - acc: 0.9636 - val_loss: 0.1463 - val_acc: 0.9619\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14629 to 0.14627, saving model to weights.best.h5py\n",
      "Epoch 3/5\n",
      "107710/107710 [==============================] - 627s 6ms/step - loss: 0.1407 - acc: 0.9636 - val_loss: 0.1462 - val_acc: 0.9619\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "\n",
      "Epoch 00003: val_loss improved from 0.14627 to 0.14624, saving model to weights.best.h5py\n",
      "Epoch 4/5\n",
      "107710/107710 [==============================] - 624s 6ms/step - loss: 0.1406 - acc: 0.9636 - val_loss: 0.1462 - val_acc: 0.9619\n",
      "roc-auc: 0.5 - roc-auc_val: 0.5                                                                                                    \n",
      "\n",
      "Epoch 00004: val_loss improved from 0.14624 to 0.14622, saving model to weights.best.h5py\n",
      "Epoch 5/5\n",
      " 23400/107710 [=====>........................] - ETA: 8:22 - loss: 0.1451 - acc: 0.962"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-70a5eef80097>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m          \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroc_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                         \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mprev_total_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\b'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m                 \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                 \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mevent_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send (zmq\\backend\\cython\\socket.c:7305)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send (zmq\\backend\\cython\\socket.c:7048)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy (zmq\\backend\\cython\\socket.c:2920)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cp\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq\\backend\\cython\\socket.c:9621)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "x_val = comments_train[107710:]\n",
    "y_val = labels_train[107710:]\n",
    "x_train = comments_train[:107710]\n",
    "y_train = labels_train[:107710]\n",
    "\n",
    "\n",
    "model.fit(x_train,y_train, validation_data=(x_val, y_val), epochs=5, batch_size=50, verbose=1,\\\n",
    "          callbacks=[roc_callback(training_data=(x_train,y_train),validation_data=(x_val, y_val)), checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre = model.predict(pad_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(comments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.30993235  0.09459998  0.22915576  0.0549183   0.21933208  0.09206153]\n"
     ]
    }
   ],
   "source": [
    "print(pre[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41676765809861677"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = []\n",
    "for i in range(5):\n",
    "    roc_auc.append(roc_auc_score(labels_test.iloc[:,i], predictions[:,i]))\n",
    "    \n",
    "sum(roc_auc)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(pre, index=test_data['id'],\\\n",
    "                          columns=['toxic','severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'])\n",
    "submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
